For as long as I can remember, I have been fascinated by robots and robotics. At a very young age, my idea of a robot was a combination of a human and a machine. I thought that robots are just humans with a computer inside of their brain, which controlled their external mechanical parts. As I grew older and began using my first computer, I was shocked by how fast computers were at processing information and complex calculations. It was then when I started thinking about ways in which we could utilize the processing power of computers to assist humans in everyday tasks. Very soon after, smartphones became a thing. Their popularity rapidly increased and each year the world was presented with new, more powerful devices, and a wide spectrum of new technologies. At this point, phones were not used only for communication, but they served as maps, cameras, tools for entertainment, banking, social interaction, notebooks, calendars, and replaced countless other tools, simply by utilizing the power of computers. Throughout the years as an IM student, I had the opportunity to familiarize myself with the world of sensors. Although I was familiar with the most basic principles, it was fascinating to see how many different ways a computer could perceive its environment. Very similarly to how I was shocked as a kid by the information processing speed of computers, now I was surprised by how many “senses” computers have simply by reading data from appropriate sensors. After studying historical surveillance systems I became interested in modern surveillance technologies and which sensors are used for that purpose. One specific sensor which grabbed my attention is the LiDAR scanner. Similar to how radar and sonar use radio and sound waves to measure distances and scan surfaces, a LiDAR sensor uses light waves for the same purpose. However, unlike sonar and radar, with the use of LiDAR, a computer can scan and simulate a three-dimensional environment. This sensor is used as a method of surveillance that can simulate and actively surveil any space in three dimensions, unlike the most commonly used cameras which only show a two-dimensional image. However, since this technology is relatively new, one such sensor can be extremely costly, priced at 5000$ and more. With this project, I intend to use a computer to enhance the human perception of the environment. By combining the computer with a LiDAR sensor and augmented reality, I hope to achieve a high level of environment-computer-human interaction. The user would be able to perceive their surroundings in three dimensions on an augmented reality visor, in any conditions which would normally limit or block visibility. The secondary goal is to develop a piece of technology that would successfully achieve its primary goal, while at the same time being affordable. I imagine that this project would have real-world applications and I intend for it to be used by people who engage in activities in low visibility environments.
